{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"right\"><i>COM418 - Computers and Music</i></div>\n",
    "<div align=\"right\"><a href=\"https://people.epfl.ch/paolo.prandoni\">Paolo Prandoni</a>, <a href=\"https://www.epfl.ch/labs/lcav/\">LCAV, EPFL</a></div>\n",
    "\n",
    "<p style=\"font-size: 30pt; font-weight: bold; color: #B51F1F;\">Measuring Sound </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "import IPython\n",
    "\n",
    "import matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = (14,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def analog_response(b, a, sf, dB=-70, half=True, points=8000, axis=None, color='C0'):\n",
    "    \"\"\"plot the magnitude response of a digital filter on a log-log scale\"\"\"\n",
    "    F0 = 10\n",
    "    EPS = 1e-20\n",
    "    w = np.linspace(2 * np.pi * F0 / sf, np.pi, points)\n",
    "    A, B = np.zeros(points, dtype='complex'), np.zeros(points, dtype='complex')\n",
    "    for n, bn in enumerate(b):\n",
    "        B += bn * np.exp(-1j * n * w)\n",
    "    for n, an in enumerate(a):\n",
    "        A += an * np.exp(-1j * n * w)\n",
    "    M = 20 * np.log10(np.abs(np.where(B == 0, EPS, B) / (np.where(A == 0, EPS, A))))\n",
    "    \n",
    "    if axis is None:\n",
    "        _, axis = plt.subplots()\n",
    "    axis.plot(np.linspace(F0, sf / 2, points), M, color, lw=2)\n",
    "    axis.set_xscale('log')\n",
    "    axis.set_ylabel('dB', color='C0')\n",
    "    axis.grid(b=True, which='both')    \n",
    "    axis.axis('tight')\n",
    "    axis.set_ylim([max(dB, min(M)), None])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# we will need some real-world audio for some examples. \n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Brandenburg concerto #1, mono, 8 kHz\n",
    "audio_sample_sf, audio_sample = wavfile.read(\"snd/brand1.wav\")\n",
    "audio_sample = audio_sample / 32767.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# The many incarnations of sound\n",
    "\n",
    "Sound: a vibration that propagates through an elastic medium as an acoustic wave\n",
    "\n",
    "The information carried by a sound can be encoded in many forms:\n",
    " * as a pressure wave in air with amplitude measured in pascal\n",
    " * as an electric signal produced by a microphone measured in volts\n",
    " * as a groove depth in a vinyl record, measured in mm\n",
    " * as a space-varying magnetic field on a tape coated with ferromagnetic particles \n",
    " * as a discrete-time signal, stored as a sequence of integer values in digital memory\n",
    " \n",
    "These alternate representations are at least in principle equivalent and can be converted into one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring sound\n",
    "\n",
    "Sound is a multi-faceted phenomenon:\n",
    " * time duration\n",
    " * amplitude variations\n",
    " * frequency content\n",
    " \n",
    "Here, we are interested in a variety of quantitative metrics that are useful in audio recording and production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Physical vs perceptual metrics\n",
    "\n",
    " * physical metrics are based on the intrinsic properties of a signal, independently of its nature\n",
    " * perceptual metrics take into account the human auditory system\n",
    " \n",
    "<br>\n",
    "\n",
    "\n",
    "Examples:\n",
    " * perceived loudness is related to the power of the signal, but in very complicated ways\n",
    " * energy outside of human hearing range (20 Hz to 20 kHz) is irrelevant in perceptual metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Common metrics for signals\n",
    "\n",
    "Given a continous- or discrete-time signal (audio or not), we are interested in quantitative metrics that help us describe:\n",
    "\n",
    "  * the presence of DC bias (balance)\n",
    "  * the amplitude excursion (dynamic range)\n",
    "  * the power at different time scales (related to loudness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Average (DC value)\n",
    "\n",
    "$$\n",
    "    \\bar{x} \\triangleq \\frac{1}{T}\\int_0^T x(t) dt \\quad \\triangleq \\frac{1}{N}\\sum_{n=0}^{N-1} x[n]\n",
    "$$\n",
    "\n",
    "In general, audio signals are zero-mean, that is, the distribution of their amplitude values is balanced around zero. \n",
    "\n",
    "If this is not the case, we say that the signal has a _DC bias_ ; this is bad because:\n",
    " * it needlessly reduced the _input_ dynamic range (problems with recording, AD conversion, etc)\n",
    " * it reduces the _output_ dynamic range (speakers should oscillate around rest position)\n",
    " * it wastes energy in reproduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Peak amplitude and peak-to-peak\n",
    "\n",
    "The maximum amplitude excursion of a balanced sound signal $x(t)$ is called its **peak amplitude**\n",
    "\n",
    "$$\n",
    "    x_\\mathrm{peak} \\triangleq \\max_t |x(t)| \\quad \\triangleq \\max_n |x[n]|\n",
    "$$\n",
    "\n",
    "\n",
    "For unbalanced signals we use the peak-to-peak (p-p) value\n",
    "\n",
    "$$\n",
    "    x_\\mathrm{p-p} \\triangleq \\max_t x(t) - \\min_t x(t) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## True peak (discrete-time signals)\n",
    "\n",
    "The peak value of a discrete-time signals and that of its continuous-time version may not coincide; in these cases we refer to the continuous-time peak value as the **true peak**.  \n",
    "\n",
    "Example: $x(t) = \\cos(2\\pi f + \\pi / 4)$\n",
    "\n",
    " * $x_\\mathrm{peak} = 1$, independently of $f$\n",
    " * sample at $F_s = 4f$: $\\hat{x}[n] = x(n/F_s) = \\cos(\\pi n / 2 + \\pi / 4) \\Rightarrow |\\hat{x}[n]| = 1/\\sqrt{2}$\n",
    " * $\\hat{x}_\\mathrm{peak} = 1/\\sqrt{2}$\n",
    " * $20\\log_{10}(\\hat{x}_\\mathrm{peak}/x_\\mathrm{peak}) = -3~\\mathrm{dB}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def x(t):\n",
    "    return np.cos(np.pi/4 + 2 * np.pi * t)\n",
    "\n",
    "t = np.arange(0, 3, 0.01)\n",
    "plt.plot(t, x(t));\n",
    "plt.plot(t[::25], x(t[::25]), 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Question: what is the maximum possible gap between the discrete-time peak value and the true peak for an arbitrary signal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Root Mean Square (RMS)\n",
    "\n",
    "Many properties of a sound signal correlate more closely to the _power_ of the signal rather than to its max amplitude. \n",
    "\n",
    "Key concepts:\n",
    "  * power is energy over time: **always associated to a time window**\n",
    "  * power of a sound _source_ not the same as _measured_ power (decays as $1/r^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The root-mean-square (RMS) value of a signal is defined as\n",
    " \n",
    "\n",
    "$$\n",
    "    x_{\\mathrm{RMS}} \\triangleq \\sqrt{\\frac{1}{T}\\int_{0}^{T} |x(t)|^2 dt} \\quad \\triangleq \\sqrt{\\frac{1}{N}\\sum_{n=0}^{N-1} |x[n]|^2}.\n",
    "$$\n",
    "\n",
    "Assume $x(t)$ is measured in Volts and the RMS analysis window is $T$ seconds:\n",
    " * $x_{\\mathrm{RMS}}$ is the equivalent DC value that provides the same power as $x(t)$ to a resistive load\n",
    " * $(x_{\\mathrm{RMS}})^2$ is the power of the signal to a $1~\\Omega$ resistive load \n",
    " * short window:  $x_{\\mathrm{RMS}} \\rightarrow x_\\mathrm{peak}$ (peak power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Caution: you will sometimes see this formula:\n",
    "\n",
    "$$\n",
    "    x_{\\mathrm{RMS}} = \\frac{x_\\mathrm{peak}}{\\sqrt{2}}\n",
    "$$\n",
    "\n",
    "**this is only true for pure sinusoids**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crest factor and peak-to-average power ratio (PAPR)\n",
    "\n",
    "$$\n",
    "    C = \\frac{x_\\mathrm{peak}}{x_\\mathrm{RMS}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\mbox{PAPR} = C^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notable waveforms\n",
    "<img src=\"img/waveforms.png\" alt=\"wikipedia\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relation to mathematical norms\n",
    "\n",
    "When looking at signals as vectors:\n",
    "\n",
    " * $x_\\mathrm{peak} = \\| \\mathbf{x} \\|_\\infty$\n",
    " * $x_\\mathrm{RMS} = \\| \\mathbf{x} \\|_2 / \\sqrt{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_sample, rate=audio_sample_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(x, axis=None):\n",
    "    n_max, n_min = np.argmax(x), np.argmin(x)\n",
    "    n_peak = n_max if np.abs(x[n_max]) > np.abs(x[n_min]) else n_min\n",
    "    dc, rms = np.mean(x), np.sqrt(np.mean(x ** 2))\n",
    "    m = {\n",
    "        \"DC\": dc, \n",
    "        \"peak_location\": n_peak,\n",
    "        \"peak\": x[n_peak],\n",
    "        \"p-p\": x[n_max] - x[n_min],\n",
    "        \"RMS\": rms\n",
    "    }\n",
    "    if axis is not None:\n",
    "        axis.plot(x, color='lightgray', linewidth=0.5)\n",
    "        axis.axhline(y=dc, color='C2', label=f\"DC: {dc:.3f}\")    \n",
    "        axis.axhline(y=rms, color='C3', label=f\"RMS: {rms:.3f}\")    \n",
    "        axis.plot((n_peak, n_peak), (dc, x[n_peak]), color='C0', label=f\"peak = {x[n_peak]:.3f}\")\n",
    "        axis.axhline(y=x[n_max], color='C4') \n",
    "        axis.axhline(y=x[n_min], color='C4')\n",
    "        axis.plot((0, 0), (x[n_max], x[n_min]), color='C4', label=f\"p-p = {(x[n_max] - x[n_min]):.3f}\")\n",
    "        axis.plot(0, 0, linewidth=0, label=f'PAPR: {20 * np.log10(np.abs(x[n_peak])/rms):.2f} dB')\n",
    "        axis.grid()\n",
    "        axis.legend(loc='lower right')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(audio_sample[8000:16000], plt.subplots()[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Refresher: the decibel (dB)\n",
    "\n",
    "Historically, a logarithmic measure of **power loss** over telecommunication cables. One dB was the average power loss over 1 mile of cable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring power ratios\n",
    "\n",
    "In general, for a power quantity $P$ and a _reference_ power $P_0$, \n",
    "\n",
    "$$\n",
    "    L_P = 10\\log_{10}\\frac{P}{P_0}\n",
    "$$\n",
    "\n",
    " * always relative to a reference value\n",
    " * positive for gain, negative for loss\n",
    " * +3 dB = twice the power\n",
    " * -3 dB = half the power\n",
    " * +10 dB = ten times the power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To go back to linear units (Watts)\n",
    "\n",
    "$$\n",
    "    P = P_0 \\cdot 10^{L_P/10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring amplitude ratios\n",
    "\n",
    "In most engineering applications, energy or power are proportional to the square of an amplitude value: $P \\propto v^2$; some examples:\n",
    " * $P = V^2/R$ in electrical circuits\n",
    " * $E = mv^2/2$ for the kinetic energy\n",
    " * $I = p^2/Z$ for sound intensity. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For amplitude ratios:\n",
    "\n",
    "$$\n",
    "    L_F = 10\\log_{10}\\frac{P}{P_0} = 10\\log_{10}\\frac{v^2}{v_0^2} = 20\\log_{10}\\frac{v}{v_0}\n",
    "$$\n",
    "\n",
    " * +6 dB = twice the value\n",
    " * -6 dB = half the value\n",
    " * +20 dB = ten times the value\n",
    " \n",
    "To go back to linear units\n",
    "\n",
    "$$\n",
    "    v = v_0 \\cdot 10^{L_P/20}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specialized units\n",
    "\n",
    "  * **dBm** : power ratio with reference $P_0 = 1~\\mathrm{mW}$\n",
    "  * **dBu** : voltage (RMS) ratio with reference $v_0 = 0.7746~\\mathrm{V}$ ($v_0$ is the voltage drop across a $600~\\Omega$ resistor dissipating $1~\\mathrm{mW}$; so, numerically, dBu = dBm)\n",
    "  * **dBV** : voltage (RMS) ratio with reference $v_0 = 1~\\mathrm{V}$ (dBV = dBu + 2.2)\n",
    "  * **dBFS**: _peak_ amplitude ratio for digital signals at $R$ bps with reference $v_0 = 2^R$; always negative.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example: mic and Line levels:**\n",
    "\n",
    " * mic level: between -60 and -40 dBu (~1 mV RMS)\n",
    " * line level (consumer): 4 dBu (~1 V RMS) \n",
    " * line level (pro): -10 dBV (-7.8 dBu, ~0.3 V RMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Physical audio measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is sound? (again)\n",
    "\n",
    "Sound: a vibration that propagates through a medium as an acoustic wave. Key terms:\n",
    "\n",
    " * vibration: displacement around an equilibrium point\n",
    " * acoustic wave (idealized): energy propagation without heat or mass changes (adiabatic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The acoustic wave\n",
    "\n",
    "<img src=\"img/wave.gif\" alt=\"https://www.acs.psu.edu/drussell/Demos/phase-p-u/phase-p-u.html\" style=\"float: right; width: 400px; margin: 20px 30px;\"/>\n",
    "\n",
    "The initial displacement is caused by a **force** acting on the medium. This creates a **pressure** measured in pascals ($1~\\mathrm{Pa} = 1~\\mathrm{N/m^2}$)\n",
    "\n",
    "The pressure causes particles in the medium to move around their equilibrium point with a (putative) **particle velocity** $\\nu$\n",
    "\n",
    "Interaction between neighboring particles creates an energy wave whose **propagations speed** $c$ (in $\\mathrm{m/s}$) depends on the properties of the medium \n",
    "\n",
    "Importantly, particle velocity and propagation speed are not the same thing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general, we are interested in sound that:\n",
    "  \n",
    " * propagates in air $\\rightarrow$ $c \\approx 343~\\mathrm{m/s}$\n",
    " * is audible $\\rightarrow$ frequency content between $16~\\mathrm{Hz}$ and $20~\\mathrm{kHz}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Amplitude measures\n",
    "\n",
    "### Sound Pressure\n",
    "\n",
    "Sound propagation in air on earth takes place via a time-varying deviation from the **atmospheric pressure** (i.e. the weight of the air in the atmosphere due to earth's gravitational pull; on average this pressure is $101,325~\\mathrm{Pa}$, a value also known as 1 atmosphere). **Sound pressure** is the scalar value of the deviation from atmospheric pressure at the point of measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " * The smallest sound pressure value detectable by the human ear is called the **threshold of hearing** and it is conventionally defined as $p_0 = 20~\\mu \\mathrm{Pa} = 20 \\cdot 10^{-6}~\\mathrm{Pa}$ \n",
    " * The (theoretical) loudest sound possible on earth would cause the local pressure to drop to zero, for a sound pressure value equal to 1 atmosphere.\n",
    " * sound pressure is _related_ to a subjective loudness \"scale\", but in complicated ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SPL\n",
    "\n",
    "The softest and loudest sounds are separated by 11 orders of magnitude in pressure amplitude so it's customary to use a log scale. The **sound pressure level (SPL)** is defined as the difference in decibels between the pressure level at the point of measurement and the threshold of hearing:\n",
    "\n",
    "$$\n",
    "    L_p = 20\\log_{10}\\frac{p}{p_0}\n",
    "$$\n",
    "\n",
    " * $1~\\mathrm{Pa} = 94~\\mathrm{dB~SPL}$\n",
    " * SPLs over $120~\\mathrm{dB}$ can quickly provoke permanent hearing loss.\n",
    " * a particle of free air exposed to a sinusoidal sound pressure of $1~\\mathrm{Pa}$ moves back and forth with a velocity amplitude of about $2~\\mathrm{mm/s}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/spl.png\" alt=\"wikipedia\" style=\"width: 900px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Question: what is the SPL of the loudest possible sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Microphones\n",
    "\n",
    "<img src=\"img/mic.jpg\" alt=\"mic\" style=\"float: right; width: 150px; margin: 10px 30px;\"/>\n",
    "\n",
    "Microphones convert _pressure_ levels to voltage levels.\n",
    "\n",
    "Key ratings are **sensitivity**, measured in dBV/Pa or mV/Pa, and max SPL (after which the mic distorts). High-sensitivity mics are called \"hot\" (they quickly overload preamp stages)\n",
    "\n",
    "<br>\n",
    "\n",
    "| | | |\n",
    "|--|--|--|\n",
    "|  |sensitivity|max SPL|\n",
    "|Shure SM58 | –54.5 dBV/Pa (1.85 mV/Pa) | 150 dB |\n",
    "|Royer R-121 | -47 dBV/Pa (4.5 mV/Pa) | 135 dB|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Headphones\n",
    "\n",
    "<img src=\"img/headphones.jpg\" alt=\"headphones\" style=\"float: right; width: 250px;\"/>\n",
    "\n",
    "What is the SPL generated by your headphones? It depends on your volume settings! Comfortable level: 60 to 80 dB SPL\n",
    "\n",
    "Headphones are rated in terms of **sensitivity**, measured in SPL/V or SPL/mW. High sensitivity: less power to achieve target SPL but more fragile design\n",
    "\n",
    "<br> \n",
    "\n",
    "| | |\n",
    "|--|--|\n",
    "|  |sensitivity|\n",
    "|Sennheiser HD 820 | 103 dB/V(RMS) @ 1 kHz |\n",
    "|Apple Earpods | 117.96 dB/V| \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Energy measures\n",
    "\n",
    "### The acoustic impedance\n",
    "\n",
    "Every medium that transmits sound exhibits a \"resistance\" to wave propagation, called the **acoustic impedance** $Z = \\rho c$\n",
    " * $\\rho$ is the medium density ($kg/m^3$)\n",
    " * $c$ is the speed of sound in the medium ($m/s$)\n",
    " * both $\\rho$ and $c$ depend on temperature and frequency\n",
    " * $Z$ is measured in Rayls (Ry). ie. $Ns/m^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Examples:\n",
    " * air: $Z \\approx 400~\\mathrm{Ry}$\n",
    " * water: $Z \\approx 1.48\\cdot 10^6~\\mathrm{Ry}$\n",
    " * steel: $Z \\approx 45\\cdot 10^6~\\mathrm{Ry}$\n",
    "\n",
    "Particle velocity and pressure are related as $\\nu = p/Z$. Consequences:\n",
    " * for the same pressure, air particles move a lot more than water particles\n",
    " * at the interface between different materials: impedance mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sound Intensity\n",
    "\n",
    "Sound intensity measures the average rate of flow of energy through a unit area normal to the direction of wave propagation ($W/m^2$). It is a **vector** measurement that relates the scalar pressure value to the vector particle velocity across the point of measurement: \n",
    "\n",
    "$$ \n",
    "    \\mathbf{I} = p \\boldsymbol{\\nu}\n",
    "$$\n",
    "\n",
    "Sound intensity is not directly relevant to audio applications since both microphones and human ears are only sensitive to (scalar) pressure. But it's an important measure because:\n",
    " \n",
    " * it shows the way sound pressure propagates in space (where to place microphones)\n",
    " * it accounts for the differences in propagation medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall $\\nu = p/Z$; then $I = p^2/Z$, which relates intensity to pressure (on an **averaged** scalar level). \n",
    "\n",
    "More generally, sound pressure and sound intensity are related by the acoustic equivalent of Ohm's law:\n",
    "\n",
    " * pressure is akin to voltage\n",
    " * particle velocity is akin to current\n",
    " * acoustic impedance is akin to resistance\n",
    " * intensity is akin to power\n",
    " \n",
    "With this $v=Ri$ becomes $p = Z\\nu$ and $W = vi=v^2/R$ becomes $I = p^2/Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SIL\n",
    "\n",
    "As for pressure, the large dynamic range of occurring intensities leads to a logarithmic scale; the **sound intensity level (SIL)** is defined as the difference in decibels between the measurend intensity and a reference value of $1~pW/m^2$ \n",
    "\n",
    "$$\n",
    "    L_I = 10\\log_{10}\\frac{I}{I_0}\n",
    "$$\n",
    "\n",
    "Note that intensity is a power measure, hence the factor of $10$ before the log. Since $I \\propto p^2$, with the above choice for $I_0$ SPL and SIL coincide:\n",
    "\n",
    "$$\n",
    "    L_I = L_p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple sources\n",
    "\n",
    "Intensities of multiple sources combine additively as *vectors*. In terms of averaged magnitude it's... complicated; the result depends on\n",
    " * type of waveforms (planar, spherical)\n",
    " * phase coherence\n",
    " * sound field (diffuse, reverberant, etc)\n",
    "\n",
    "Simplified approach: assume each source is independent white noise:\n",
    " * $I_\\mathrm{total} = \\sum_n I_n$\n",
    " * $N$ equal sources: $I_\\mathrm{total} = NI$, so $L_\\mathrm{total} = L_I + 10\\log_{10} N$\n",
    " * 2 sources: +3 dB\n",
    " * 10 sources: +10 dB (twice as **loud**...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Perceptual audio measurements\n",
    "\n",
    "We are primarily concerned with **loudness**, which is is the _subjective_ perception of sound pressure.\n",
    "\n",
    "Perceptual loudness is _related_ to SPL, but also to the frequency content and to the duration of a sound in complicated ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loudness (for sinusoidal test signals)\n",
    "\n",
    "<img src=\"img/loudness.gif\" alt=\"loudness\" style=\"float: right; width: 600px; margin: 20px 30px;\"/>\n",
    "\n",
    "\n",
    "### Equal Loudness curves\n",
    "\n",
    "Experiment: generate a 1 KHz sinusoid at $L_p$ SPL; change the frequency and ask the subject to adjust the \"volume\" (i.e. the SPL) to match the original tone. For every $L_p$ value, we obtain an equal-loudness curve as shown in the plot:\n",
    "\n",
    " * relation of loudness to SPL (or SIL) highly frequency-dependent\n",
    " * low sensitivity to low frequencies\n",
    " * maximum sensitivity between 3 and 4 KHz\n",
    " \n",
    "(Fletcher and Munson, 1933)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The phon\n",
    "\n",
    "The equal-loudness curves are parametrized in **phons** , a logarithmic measure of loudness. \n",
    " * at $f = 1~\\mathrm{kHz}$, phons coincide with SPL: $L_N = L_p = L_I$ \n",
    " * at other frequencies, find $L_N$ from the equal loudness curve that passes through the $(f, L_p)$ point\n",
    "\n",
    "<img src=\"img/loudness.gif\" alt=\"loudness\" style=\"float: left; width: 400px; margin: 30px 40px;\"/>\n",
    "\n",
    "Subjectively, to double the perceived loudness of a sinusoid we need to move up the phon scale by around 10 dB; since 10 independent sources increase the SIL by 10 dB, the rule of thumb is that you need 10 violins to double the perceived loudness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The sone\n",
    "\n",
    "<img src=\"img/sones.jpg\" alt=\"loudness\" style=\"float: right; width: 400px; margin: 0px 30px;\"/>\n",
    "\n",
    "The sone is a measure of relative loudness on a _linear_ scale with 1 phone equivalent to 40 phons as the reference. \n",
    "\n",
    "Since doubling the loudness corresponds to adding 10 dB to the phon value $L_N$, the loudness in sones is \n",
    "\n",
    "$$\n",
    "    N = \\begin{cases} \n",
    "        2^{(L_N - 40)/10} & L_N \\ge 40~\\mathrm{dB} \\\\\n",
    "        (L_N / 40)^{2.86} - 0.005 & L_N < 40~\\mathrm{dB}\n",
    "       \\end{cases}\n",
    "$$\n",
    "\n",
    "The change in the formula for small sound levels is due to the different sensitivity of the hearing system in the presence of quieter sounds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Steven's power law\n",
    "\n",
    "A common approximation linking loudness (in sones) to sound pressure (in pascals) is\n",
    "\n",
    "$$\n",
    "    \\frac{N_1}{N_0} = \\left( \\frac{p_1}{p_0}\\right) ^{0.67}\n",
    "$$\n",
    "\n",
    "since $3^{0.67}\\approx 2$, the sensation of loudness is doubled every time the pressure is multiplied by 3.\n",
    "\n",
    "This exponential law between stimulus and its perception seems to apply to most sensory experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hearing regions\n",
    "\n",
    "<img src=\"img/soundareas.png\" alt=\"loudness\" style=\"width: 800px; margin: 20px 30px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why do people like LOUD music? \n",
    "\n",
    " * “Loud music saturates the auditory system causing neurons to fire at their maximum rate -- a brain state qualitatively different from when they are firing at normal rates.” _(Levitin, Your Brain on Music)_\n",
    " * the equal-loudness curves are _flatter_ at higher volumes: more \"presence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other perceptual metrics\n",
    "\n",
    " * **sharpness** (acums): relates to the high frequency content of a sound. E.g. difference between vacuum cleaner and washing machine.\n",
    " * **fluctuation strength** (vacils): measures slow amplitude modulations (e.g. beatings) at less than 20 Hz\n",
    " * **roughness** (asper): measures fast amplitude modulations (between 20 and 300 Hz, limit of perception)\n",
    " * **PA** (psychoacoustic annoyance): function of previous three metrics, attempts to quantify how annoying a sound is \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Physical measurements for recording/production\n",
    "\n",
    "Main goal is avoid **distortion** which happens when signal levels exceed the equipment's range.  \n",
    "\n",
    "We need to monitor\n",
    " * the audio dynamic range (peak values)\n",
    " * the short-term and long-term power (RMS values)\n",
    "\n",
    "keeping in mind the equipment's\n",
    " * saturation region (or clipping ceiling for digital) \n",
    " * noise floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Analog equipment\n",
    "\n",
    "Analog metrics are still interesing because many of the digital metrics are based on analog practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Analog systems have a saturation region before where distortion is incremental and acoustically acceptable.\n",
    "\n",
    "\"Hot\" analog recordings (with meters in the red) can be good; do not try that with digital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipFig, clipAx = plt.subplots()\n",
    "x = np.linspace(-1.5, 1.5, 1000)\n",
    "clipAx.plot(x, np.clip(x, -1, 1), label=\"clipping\")\n",
    "clipAx.plot(x, 2 * np.arctan(2 * x) / np.pi, label=\"saturation\");\n",
    "clipAx.grid()\n",
    "clipAx.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Power level: the VU meter\n",
    "\n",
    " * maximum input level for analog gear: about $+26~\\mathrm{dBu}$ (12V RMS)\n",
    " * noise floor: at least $-90~\\mathrm{dB}$ in pro equipment\n",
    " * target level for line signals: $+4~\\mathrm{dBu}$ (1V RMS)\n",
    " * $20~\\mathrm{dB}$ **headroom**\n",
    " * distortion is progressive in headroom\n",
    " * short moments \"in the red\" are OK\n",
    "\n",
    "<img src=\"img/vu-meter.jpg\" alt=\"vumeter\" style=\"float: right; width: 300px; margin: 20px 30px;\"/>\n",
    "\n",
    "VU meters (Volume Unit) compute the RMS via mechanical integration over approximately 300ms. They are calibrated so that zero corresponds to $+4~\\mathrm{dBu}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Peak levels: the PPM\n",
    "\n",
    "\n",
    "Peak Programme Meters are analog devices that monitor the amplitude of the input. \n",
    "\n",
    "Essentially VU meters with:\n",
    " * fast integration time (as $T\\rightarrow 0, x_{\\mathrm{RMS}} \\rightarrow x_\\mathrm{peak}$)\n",
    " * quick rise with no overshoot\n",
    " * slow release time\n",
    "\n",
    "<img src=\"img/ppm.jpg\" alt=\"ppm\" style=\"float: right; width: 300px; margin: 0px 30px;\"/>\n",
    "\n",
    "Because of the integration time, PPMs under-read bursts shorter than 10 ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modeling analog meters\n",
    "\n",
    "Mechanical integration can be modeled digitally via a leaky integrator.\n",
    "\n",
    "The needle _ballistics_ is different for VU meters and for PPMs:\n",
    " * VU meters have a long integration window and similar rise and fall dynamics\n",
    " * PPMs must rise fast but fall slowly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analog_meter(x, rise, fall):\n",
    "    ppm = np.r_[0, (x * x)[:-1]]\n",
    "    for n in range(1, len(x)):\n",
    "        a = rise if ppm[n] > ppm[n-1] else fall\n",
    "        ppm[n] = a * ppm[n] + (1 - a) * ppm[n-1]\n",
    "    return np.sqrt(ppm)\n",
    "\n",
    "def vu_meter(x, c=0.001):\n",
    "    return analog_meter(x, rise=c, fall=c)\n",
    "                \n",
    "def ppm(x, rc=0.9, fc=0.0001):\n",
    "    return analog_meter(x, rise=rc, fall=fc)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clip = audio_sample[8000:16000]\n",
    "plt.plot(np.abs(clip), color='lightgray', linewidth=0.5)\n",
    "plt.axhline(y=np.sqrt(np.mean(clip * clip)), color='C0', label='global RMS')\n",
    "plt.plot(vu_meter(clip), color='C2', linewidth=3, label='RMS estimate')\n",
    "plt.plot(vu_meter(clip, c=0.0001), color='C1', label='slow estimate')\n",
    "plt.plot(vu_meter(clip, c=0.01), color='C4', label='fast estimate')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clip = audio_sample\n",
    "plt.plot(np.abs(clip), color='lightgray', linewidth=0.5)\n",
    "plt.axhline(y=np.sqrt(np.mean(clip * clip)), color='C0', label='global RMS')\n",
    "plt.plot(vu_meter(clip), color='C2', linewidth=3, label='RMS estimate')\n",
    "plt.plot(vu_meter(clip, c=0.0001), color='C1', label='slow estimate')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clip = audio_sample[8000:16000]\n",
    "plt.plot(np.abs(clip), color='lightgray', linewidth=0.5)\n",
    "plt.plot(ppm(clip), color='C2', linewidth=3, label='PPM estimate')\n",
    "plt.plot(ppm(clip, rc=0.4), color='C1', label='slow rise: under-read')\n",
    "plt.plot(ppm(clip, fc=0.01), color='C4', label='fast decay: too busy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clip = audio_sample\n",
    "plt.plot(np.abs(clip), color='lightgray', linewidth=0.5)\n",
    "plt.plot(ppm(clip, fc=0.0001), color='C2', linewidth=3, label='PPM estimate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Digital equipment\n",
    "\n",
    "AD converters are hard clippers; digital distortion is VERY harsh. \n",
    "\n",
    "We **must** remain below max level (i.e. below $0~\\mathrm{dBFS}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipFig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "A digital representation with $R$ bits per sample has a dynamic range equal to \n",
    "\n",
    "$$\n",
    "    20 \\log_{10}\\frac{2^R}{1} \\approx 6R~\\mathrm{dB}\n",
    "$$\n",
    "\n",
    "In digital audio we must ensure that all samples are within the range of a $R$-bit word. Hence we measure the _peak_ value against the largest possible value:\n",
    "\n",
    "$$\n",
    "    L_x = 20 \\log_{10}\\frac{x_\\mathrm{peak}}{2^R}~\\mathrm{dBFS} \\qquad \\mbox{always $< 0$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Peak and power levels: dBFS\n",
    "\n",
    "With $R$ bits per sample:\n",
    " * clipping point: $0~\\mathrm{dBFS}$\n",
    " * noise floor: $2^{-R} \\approx -6R~\\mathrm{dBFS}$\n",
    " * common RMS target level alignment: $0~\\mathrm{dBu} \\rightarrow -18~\\mathrm{dBFS}$ (EBU R68)\n",
    " * about 3 bits of \"margin\"\n",
    " * distortion is all or nothing; no natural headroom\n",
    "\n",
    "<center>\n",
    "<img src=\"img/dbfs.jpg\" alt=\"dbfs\" style=\"width: 600px; margin: 30px 10px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/alignment.png\" alt=\"align\" style=\"width: 500px; margin: 20px 10px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### True peak meters\n",
    "\n",
    "Estimate of true peaks:\n",
    " * oversample by a factor of $N$\n",
    " * lowpass filter (FIR) with cutoff $\\pi/N$\n",
    " * find max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPM(x, N=4):\n",
    "    y = np.zeros(len(x) * N)\n",
    "    y[::N] = x\n",
    "    y = N * sp.lfilter(*sp.ellip(4, 0.1, 40, 1 / N), y)\n",
    "    return 20 * np.log10(np.max(np.abs(y)) / np.max(np.abs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'true peak: +{TPM(audio_sample):.2f} dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "Exercise: prove that, for an input of the form $x[n]=\\cos(\\omega_0 n)$, the maximum error in true peak estimation is $20\\log_{10}(\\cos(\\omega_0/(2N))$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Perceptual measurements for recording/production\n",
    "\n",
    "Main goal: quantify **loudness,** either for safety reasons or to adjust reproduction levels.\n",
    "\n",
    "The complicated nature of loudness:\n",
    " * frequency-dependent (equal loudness countours)\n",
    " * sort-range time dependency (temporal masking of softer sounds after loud sounds)\n",
    " * long-range time dependency (desensitization to high levels)\n",
    " * perceptual \"deafness\" to irrelevant or repetitive sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/slm.jpg\" alt=\"sound level meter\" style=\"float: right; width: 350px; margin: 10px 0;\"/>\n",
    "\n",
    "## A-weighting and C-weighting (dBA, dBC)\n",
    "\n",
    "Used to assess the impact of environmental sounds and noise,  mostly for hearing damage risk measurements.\n",
    "\n",
    " * input is filtered to weigh spectrum according to perceptual impact\n",
    " * computes SPL of filtered input over user-definable window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Weighting filters:\n",
    " * **A-weighting** is based the 40-phon equal-loudness contour and it is used for moderate to low levels (40 phon is the loudness of a quiet room)\n",
    " * **C-weighting** has flatter response from 500 Hz to 2 kHz and it is used for louder levels (up to 100 dB SPL) \n",
    " * **Z-weighting** is completely flat (no weighting)\n",
    " \n",
    "The transfer function of the A and C filter responses is standardized by the IEC and the coefficients for a digital implementation can be computed via the bilinear transform. The ones used here have been obtained via the package [PyFilterbank](http://siggigue.github.io/pyfilterbank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A_weighting = (\n",
    "    np.array([ 0.234301792299513, -0.468603584599027, -0.234301792299513, 0.937207169198054, \n",
    "              -0.234301792299513, -0.468603584599027, 0.234301792299513]), \n",
    "    np.array([ 1.               , -4.113043408775871,  6.553121752655046, -4.990849294163378, \n",
    "              1.785737302937571, -0.246190595319486, 0.011224250033231]))\n",
    "\n",
    "C_weighting = (\n",
    "    np.array([ 0.197887120026393,  0, -0.395774240052787, 0,  0.197887120026393]), \n",
    "    np.array([ 1, -2.2191729140528,  1.455135878947169, -0.248496073887782, 0.012538823147272]))\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "analog_response(*A_weighting, sf=48000, axis=ax, color='C0')\n",
    "analog_response(*C_weighting, sf=48000, axis=ax, color='C1')\n",
    "ax.legend(['A-weighting','C-weighting']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LUFS \n",
    "\n",
    "Loudness Units relative to Full Scale (LUFS) is a logarithmic measure of **perceptual** loudness computed using a simple but effective psychoacoustic model of loudness perception. The algorithm has been proposed by by ITU in 2006 and the latest recommendation can be downloaded [here](https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.1770-4-201510-I!!PDF-E.pdf).\n",
    "\n",
    "It has become the most important metric in audio mastering, broadcast, and streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some history: \"loudness is money\" and the \"loudness wars\"\n",
    "\n",
    "People (apparently) prefer music that sounds loud. How do you make your track sound louder than the competition on the radio? \n",
    "\n",
    "Historically, broadcasters mandated a maximum _peak_ level for tracks. But loudness is related to RMS.\n",
    "\n",
    "You can keep the same peak and increase the RMS via **compression and limiting**, which reduces PAPR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Think of square wave vs sine wave\n",
    "\n",
    "<img src=\"img/waveforms.png\" alt=\"wikipedia\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"img/loudnesswar.jpg\" alt=\"wikipedia\" style=\"float: right; width: 300px; margin: 0px 20px;\"/>\n",
    "\n",
    "The **loudness wars** started in the 1990s; both new album and remasters tried to minimize the PAPR. Consequences:\n",
    " * loss of dynamic range (everything sounds \"squished\")\n",
    " * loss of definition (ear fatigue due to almost constant RMS)\n",
    " \n",
    "PAPR minimization was a loophole because broadcasters used to set limits on peak levels instead of limiting loudness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is how extreme compression kills the quality of a good song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio,Image, YouTubeVideo\n",
    "id='7UjQc0dM4H4'\n",
    "YouTubeVideo(id=id,width=600,height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Other example: loud commercial breaks on TV. Annoying and illegal!\n",
    "\n",
    " * EBU R 128, 2012\n",
    " * US CALM act, 2012\n",
    "\n",
    "These rulings can be enforced because of LUFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/loudnessBA.png\" alt=\"wikipedia\" style=\"float: right; width: 400px; margin: 0px 0px;\"/>\n",
    "\n",
    "Spotify (& Co) ended the loudness wars by setting a limit on _perceptual_ loudness (LUFS) rather than peak. \n",
    "\n",
    "Artificially loud tracks are scaled down until they are below the LUFS threshold:\n",
    "\n",
    "|  |  |\n",
    "|--|--|\n",
    "|Spotify | -14 LUFS |\n",
    "|Apple Music | -16 LUFS |\n",
    "|Youtube | -14 LUFS |\n",
    "|TV/Radio | -23 LUFS |\n",
    "\n",
    "Tracks mastered for maximum loudness will be played at a lower volume: dynamic range has been sacrificed for nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LUFS metrics\n",
    "\n",
    " * **LUFS M** (momentary max): momentary (peak) loudness (400 ms)\n",
    " * **LUFS S** (short term): averaged loudness over 3 seconds\n",
    " * **LUFS integrated**:  averaged loudness for the entire track/movie/program\n",
    " \n",
    "Broadcast and streaming plaform adjust for LUFS integrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The algorithm\n",
    "\n",
    "<img src=\"img/lufsbd.jpg\" alt=\"EBU\" style=\"width: 900px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### K-filter\n",
    "  * high shelf pre filter (head model)\n",
    "  * highpass filter (a bit like A-weighting)\n",
    "  * net result: eliminate frequencies below 37 Hz and boost everything over 1.5 kHz by 4 dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "b, a = [1.53512485958697, -2.69169618940638, 1.19839281085285], [1.0, -1.69065929318241, 0.73248077421585]\n",
    "analog_response(b, a, sf=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, a = [1.0, -2.0, 1.0], [1.0, -1.99004745483398, 0.99007225036621]\n",
    "analog_response(b, a, sf=48000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Two-step gating\n",
    "\n",
    "For long integration intervals, quiet or silent intervals would result in a meaningless reduction of the overall loudness. To avoid this:\n",
    "\n",
    " * RMS values are computed over overlapping 400 ms intervals\n",
    " * intervals below -70 dB are discarded\n",
    " * threshold $\\Gamma_r$ is average of surviving blocks\n",
    " * program loudness is average of blocks where RMS >  $\\Gamma_r$ - 10 dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Target levels for mastering\n",
    "\n",
    "|  |  |\n",
    "|--|--|\n",
    "|CD | -9 LUFS |\n",
    "|EDM/club tracks | -6 LUFS |\n",
    "| Vinyl | -20 to -16 LUFS |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample implementation\n",
    "\n",
    "This straightforward implementation computes the three LUFS metrics for a monophonic signal at an arbitrary sampling rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def LUFS(x, sf):\n",
    "    \"\"\"simple, single channel implementation of a LUFS meter\"\"\"\n",
    "    # compute the filter coefficients for the given sampling rate:    \n",
    "    #  1) pre-filter: 4 dB gain high shelf, crossover @ 1.5 kHz\n",
    "    w, A = 2 * np.pi * (1500.0 / sf), 10 ** (4.0 / 40)\n",
    "    c, d = np.cos(w), np.sqrt(2 * A) * np.sin(w)\n",
    "    pb = A * np.array([((A + 1) + (A - 1) * c + d), -2 * ((A - 1) + (A + 1) * c), ((A + 1) + (A - 1) * c - d)])\n",
    "    pa = np.array([(A + 1) - (A - 1) * c + d, 2 * ((A - 1) - (A + 1) * c), (A + 1) - (A - 1) * c - d])\n",
    "    #  2) weighting filter: highpass, 40 Hz cutoff, Q = 1/2, double zero at pi\n",
    "    w = 2 * np.pi * (40.0 / sf)\n",
    "    wb = np.array([1, -2, 1])\n",
    "    wa = np.array([1 + np.sin(w), -2 * np.cos(w), 1 - np.sin(w)])\n",
    "    \n",
    "    C = 10 ** (-0.691 / 10)  # -0.691 dB adjustment as per specs\n",
    "    y = C * np.square(sp.lfilter(wb, wa, sp.lfilter(pb, pa, x)))\n",
    "    \n",
    "    # compute RMS for each block\n",
    "    step = int(sf * 0.100)  # analysis blocks are 400 ms, with 75% overlap, so step is 100 ms\n",
    "    block_size = 4 * step   \n",
    "    z = np.zeros(len(x) // step)\n",
    "    for n in range(0, len(z)):\n",
    "        z[n] = np.mean(y[(n * step):(n * step + block_size)])\n",
    "    \n",
    "    # momentary LUFS (every 400 ms, no gate)\n",
    "    lufs_m = z[::4]\n",
    "    # short-term LUFS (avg over 3s, no gate)\n",
    "    lufs_s = np.array([np.mean(s) for s in np.split(z, range(30, len(z), 30))])\n",
    "    # integrated LUFS: compute the data-dependent threshold\n",
    "    gamma_r = np.mean(z[z > 0.0000001]) / 10  # kill everything under -70 dB\n",
    "    lufs_i = np.mean(z[z > gamma_r])\n",
    "    \n",
    "    return 10 * np.log10(lufs_m), 10 * np.log10(lufs_s), 10 * np.log10(lufs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clip = audio_sample[:50000]\n",
    "lufs_m, lufs_s, lufs = LUFS(clip, audio_sample_sf)\n",
    "\n",
    "_, ax1 = plt.subplots()\n",
    "ax1.plot(clip, color='lightgray');\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axhline(y=lufs, color='green', linewidth=3, label=f'LUFS: {lufs:.2f} dB')\n",
    "ax2.step(np.arange(0, len(lufs_m)) * audio_sample_sf * 0.4, lufs_m, where='post', label='LUFS M')\n",
    "ax2.step(np.arange(0, len(lufs_s)) * audio_sample_sf * 3, lufs_s, where='post', label='LUFS S')\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
